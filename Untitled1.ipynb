{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed45b7f",
   "metadata": {},
   "source": [
    "# Importing all required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import  train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler,OrdinalEncoder,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load csv file\n",
    "df = pd.read_csv('Kaggle_Training_Dataset_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop last row as it doesnt contain any information\n",
    "df=df.drop(index=[1687860])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2337c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and y for all Experiments\n",
    "X= df.drop('went_on_backorder', axis=1)\n",
    "y = df['went_on_backorder']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466cae0",
   "metadata": {},
   "source": [
    "- **Manually Encoding Target Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b53fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= y.replace({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique values in categorical columns\n",
    "categorical_col = [feature for feature in X.columns if X[feature].dtypes=='O']\n",
    "for col in categorical_col:\n",
    "    print(f\"no. of Unique values in {col} {len(X[col].unique())}\")\n",
    "    print(X[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7b1b1",
   "metadata": {},
   "source": [
    "***Report**\n",
    "- We can drop 'sku' columns as it the unique code for each product\n",
    "- Unique values does not help the algoritms to learn the patterns so it can be dropped\n",
    "- Other categorical columns are binary which can be encoded using label encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca610ad",
   "metadata": {},
   "source": [
    "**Lets create a function which can be used to drop the sku column and help to lable encode other categorical columns**\n",
    "- This function can help us to reuse for test file as well as help to use in prediction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_transformation(X):\n",
    "    X=X.drop(columns=['sku'])\n",
    "    label= LabelEncoder()\n",
    "    t = [['Yes'], ['No']]\n",
    "    label.fit(t)\n",
    "    for col in X.columns:\n",
    "        X[col]=label.transform(X[col])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b393b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeircal_col  = [feature for feature in df.columns if df[feature].dtypes!='O']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06076cb1",
   "metadata": {},
   "source": [
    "# Experiment: 1 = KNN Imputer for Null values\n",
    "**Why Robust scaler and not Standard scaler?**\n",
    "\n",
    "- Scaling the data using Robust scaler\n",
    "- Since most of the independent variables are not normally distributed we cannot use Standardscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389835b",
   "metadata": {},
   "source": [
    "**Why Robust Scaler and not Minmax?**\n",
    "\n",
    "- because most of the feature has outliers. So Minmax will scale data according to Max values which is outlier.\n",
    "- This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with robust scaler for KNN best K-selection experminet\n",
    "robustscaler = RobustScaler()\n",
    "X1 = robustscaler.fit_transform(X[numeircal_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20936ec5",
   "metadata": {},
   "source": [
    "**Why KNN Imputer?**\n",
    "\n",
    "- KNNImputer by scikit-learn is a widely used method to impute missing values. It is widely being observed as a replacement for traditional imputation techniques.\n",
    "- KNNImputer helps to impute missing values present in the observations by finding the nearest neighbors with the Euclidean distance matrix.\n",
    "- Here we Iterates through different K values and get accuracy and choose best K values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e9f47",
   "metadata": {},
   "source": [
    "**Finding the optimal n_neighbour value for KNN imputer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "# define imputer\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "strategies = [str(i) for i in [1,3,5,7,9]]\n",
    "for s in strategies:\n",
    "    pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(s))), ('m', LogisticRegression())])\n",
    "    scores = cross_val_score(pipeline, X1, y, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    print('n_neighbors= %s || accuracy (%.4f)' % (s , mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34bf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0cd8960",
   "metadata": {},
   "source": [
    "# Pipeline for KNN imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcac071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the KNN imputer with selected K-value\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=3)),\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                ('cat_transform', categorical_transformation()),\n",
    "                ('RobustScaler', RobustScaler())\n",
    "preprocessing = ColumnTransformer(transformers=[\n",
    "                ('num_pipeline',num_pipeline,numeircal_col),\n",
    "                ('cat_pipeline',cat_pipeline,categorical_col)\n",
    "            ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
